{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "kZEzjx2FrnNA",
        "6E23-oAyrsJn",
        "TqC49YVjr1OT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d1c58f1d1564d51828f64f120080645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb09eb5fca454f5dab76e26d79a12707",
              "IPY_MODEL_e9740b546b524b8aa1f593eb9b057279"
            ],
            "layout": "IPY_MODEL_08b222e597844dc2818c6bc5b9a5280b"
          }
        },
        "bb09eb5fca454f5dab76e26d79a12707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1d2726643740cca07f71bd223c26bb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_772f6598dacb49debad3e301b8d2c19a",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "e9740b546b524b8aa1f593eb9b057279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd34e3ca9084042a11501501b70b801",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9868ec6084f47a0b0f7d76514641645",
            "value": 0.9841288990499986
          }
        },
        "08b222e597844dc2818c6bc5b9a5280b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1d2726643740cca07f71bd223c26bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772f6598dacb49debad3e301b8d2c19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbd34e3ca9084042a11501501b70b801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9868ec6084f47a0b0f7d76514641645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "vBU8EeZJHZFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameters"
      ],
      "metadata": {
        "id": "OjeMesRTtlAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#PARAMETERS ARE WRONG"
      ],
      "metadata": {
        "id": "oqYCjNfguPhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformer block\n",
        "vocab_size = 100 #len(sp) #No. words in sentencepiece\n",
        "embed_dim = 128 # Hidden embedding dimension\n",
        "hidden_dim = 256 # Hidden layer size in feed forward network NEEDS TO BE DIVISIBLE BY NUMBER OF HEADS\n",
        "num_heads = 4 # Number of attention heads\n",
        "num_layers = 1  # Number of stacked decoder blocks NIL\n",
        "dropout = 0.1 #self-explanatory\n",
        "\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq2h9ySg6VIk",
        "outputId": "da478d26-94d6-4c62-924f-ba6e32242e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16 # Batch size for training\n",
        "# max_seq_len = 256 # Maximum sequence length\n",
        "lr = 1e-4 # Optimizer learning rate\n",
        "# beta1 = 0.9 # Adam beta1\n",
        "# beta2 = 0.999 # Adam beta2\n",
        "# epsilon = 1e-8 # Adam epsilon"
      ],
      "metadata": {
        "id": "d0uexXJGlXaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iter = 100 #print loss after x batches\n",
        "num_epochs = 1"
      ],
      "metadata": {
        "id": "tWUFj_SfKFS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_samples = 1000"
      ],
      "metadata": {
        "id": "ghQo96e3yt8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports and seed stuff\n"
      ],
      "metadata": {
        "id": "kZEzjx2FrnNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "!pip install datasets\n",
        "!pip install keras-preprocessing\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEJdH19buqAB",
        "outputId": "5bd8ccd1-b78f-4788-f95a-fe3856f32a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: keras-preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.23.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.16.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.32)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.29.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import math\n",
        "import sentencepiece as spm\n",
        "from datasets import load_dataset\n",
        "import string\n",
        "import time\n",
        "import wandb\n",
        "import datetime\n",
        "import os"
      ],
      "metadata": {
        "id": "2HtsR6r2p7x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"roneneldan/TinyStories\")"
      ],
      "metadata": {
        "id": "pGswkxvm2uKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae5d40c-4593-4b31-eb0a-19960680c560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "Oz13GVe-p_oA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6f33e2-404b-47ba-c0f1-1082e749aa8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7a6b8415cdb0>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tokenisation"
      ],
      "metadata": {
        "id": "6E23-oAyrsJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract samples from tinystories to train tokeniser\n",
        "sample_texts = dataset[\"train\"]['text'][:1000]\n",
        "# take 1000 samples from training set\n",
        "\n",
        "\n",
        "for i, text in enumerate(sample_texts):\n",
        "  text = text.lower().strip() # lowercase and remove whitespace\n",
        "  text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation\n",
        "  sample_texts[i] = text\n",
        "\n",
        "\n",
        "with open('sentences.txt', 'w') as f:\n",
        "  for text in sample_texts:\n",
        "    f.write(text + '\\n')\n",
        "# write samples to sentences.txt"
      ],
      "metadata": {
        "id": "9POH4alQ0ZtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sentences.txt') as f:\n",
        "    num_lines = sum(1 for line in f)\n",
        "print(num_lines)"
      ],
      "metadata": {
        "id": "io8BfXb-pdmg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e620fc-c7d9-4b3a-de34-2301062adc7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.Train(f\"--input=sentences.txt --model_prefix=sp --vocab_size=100 --model_type=unigram\")"
      ],
      "metadata": {
        "id": "Ectz3nICyp7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "class TinyStoriesTokenizer:\n",
        "\n",
        "    def __init__(self, model_path):\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        self.sp.load(model_path)\n",
        "\n",
        "    def encode(self, texts):\n",
        "        return self.sp.encode(texts, out_type=int)\n",
        "\n",
        "    def decode(self, ids):\n",
        "        return self.sp.decode_ids(ids)\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return self.sp.encode_as_pieces(text)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return self.sp.get_piece_size()\n",
        "\n",
        "tokenizer = TinyStoriesTokenizer('sp.model')"
      ],
      "metadata": {
        "id": "xaF2vzuO7F8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy('sp.model', 'tinystories_tokenizer.model')"
      ],
      "metadata": {
        "id": "MK8Rplh-6fEw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfb71c1-d371-4d38-97e3-738a01a2cd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tinystories_tokenizer.model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sp = spm.SentencePieceProcessor()\n",
        "# sp.load('tinystories_tokenizer.model')\n",
        "\n",
        "# tokenizer = TinyStoriesTokenizer(sp)"
      ],
      "metadata": {
        "id": "Wl3E-OWN7n9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset handling"
      ],
      "metadata": {
        "id": "TqC49YVjr1OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load full dataset\n",
        "full_df = pd.DataFrame.from_dict(dataset['train'])\n",
        "\n",
        "# Take 100k subsample\n",
        "df = full_df.sample(ds_samples, random_state=42)\n",
        "\n",
        "# Split data into train, validation, test\n",
        "train, test = train_test_split(df, test_size=0.1)\n",
        "train, val = train_test_split(train, test_size=0.2)\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 100\n",
        "\n",
        "# Create tokenizer\n",
        "tokenizer = TinyStoriesTokenizer('tinystories_tokenizer.model')\n",
        "\n",
        "# Lists to store tokenized batches\n",
        "train_tokens = []\n",
        "val_tokens = []\n",
        "test_tokens = []\n",
        "\n",
        "# Function to iterate through batches\n",
        "def iterate_batches(df, size):\n",
        "  for i in range(0, len(df), size):\n",
        "    yield df[i:i+size]\n",
        "\n",
        "# Train batches\n",
        "for batch in iterate_batches(train, batch_size):\n",
        "\n",
        "  texts = batch['text'].values.tolist()\n",
        "\n",
        "  tokens = tokenizer.encode(texts)\n",
        "\n",
        "  train_tokens.append(tokens)\n",
        "\n",
        "\n",
        "# Validation batches\n",
        "for batch in iterate_batches(val, batch_size):\n",
        "\n",
        "  texts = batch['text'].values.tolist()\n",
        "\n",
        "  tokens = tokenizer.encode(texts)\n",
        "\n",
        "  val_tokens.append(tokens)\n",
        "\n",
        "\n",
        "# Test batches\n",
        "for batch in iterate_batches(test, batch_size):\n",
        "\n",
        "  texts = batch['text'].values.tolist()\n",
        "\n",
        "  tokens = tokenizer.encode(texts)\n",
        "\n",
        "  test_tokens.append(tokens)"
      ],
      "metadata": {
        "id": "-HI-tV2SFEWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_tokens[0][:10])\n",
        "print(len(train_tokens[0]))"
      ],
      "metadata": {
        "id": "l_Blv2r-kGxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769e1f93-9122-460f-95bd-0a6dc3c0d192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 0, 5, 15, 18, 3, 0, 9, 7, 3, 33, 4, 76, 10, 0, 3, 0, 19, 4, 17, 73, 21, 67, 55, 21, 17, 10, 0, 3, 0, 11, 4, 65, 0, 3, 0, 5, 15, 59, 10, 20, 3, 11, 4, 32, 21, 17, 0, 3, 0, 6, 3, 9, 10, 20, 52, 22, 11, 4, 6, 0, 3, 0, 52, 22, 11, 4, 6, 81, 23, 6, 9, 27, 25, 21, 49, 15, 4, 3, 6, 19, 38, 10, 0, 73, 3, 15, 4, 6, 7, 12, 0, 3, 0, 5, 5, 25, 0, 3, 0, 9, 7, 0, 3, 0, 59, 40, 20, 52, 22, 11, 4, 6, 0, 3, 0, 5, 15, 91, 0, 3, 0, 4, 23, 19, 5, 32, 10, 3, 0, 9, 7, 56, 52, 22, 11, 4, 6, 0, 3, 0, 4, 42, 16, 6, 10, 37, 3, 35, 20, 23, 26, 5, 35, 0, 3, 0, 19, 4, 52, 22, 11, 4, 6, 23, 6, 9, 27, 25, 10, 21, 13, 23, 26, 5, 35, 0, 3, 0, 5, 32, 0, 61, 3, 9, 10, 39, 5, 5, 12, 0, 3, 0, 9, 7, 91, 0, 3, 0, 19, 4, 28, 7, 44, 10, 21, 3, 6, 8, 17, 13, 52, 22, 11, 4, 6, 0, 3, 0, 19, 4, 3, 6, 7, 25, 4, 10, 37, 93, 3, 0, 5, 15, 0, 3, 0, 19, 4, 42, 16, 6, 10, 37, 3, 35, 20, 39, 5, 9, 11, 0, 3, 0, 19, 4, 52, 22, 11, 4, 6, 23, 6, 9, 27, 25, 10, 21, 13, 39, 5, 9, 11, 0, 3, 0, 7, 11, 3, 0, 59, 40, 37, 88, 0, 3, 0, 5, 15, 20, 10, 25, 10, 0, 3, 0, 4, 73, 10, 56, 52, 22, 11, 4, 6, 0, 3, 0, 7, 9, 6, 0, 3, 0, 28, 7, 44, 21, 3, 6, 8, 17, 49, 15, 4, 6, 19, 38, 3, 4, 12, 10, 4, 0, 3, 0, 9, 7, 91, 0, 3, 0, 19, 4, 23, 4, 4, 10, 20, 34, 7, 12, 14, 52, 11, 28, 7, 12, 25, 38, 34, 17, 0, 3, 0, 4, 59, 10, 20, 3, 15, 4, 6, 7, 12, 3, 8, 38, 3, 35, 56, 3, 4, 33, 0, 3, 0, 9, 7, 3, 6, 19, 9, 11, 25, 10, 37, 3, 9, 10, 92, 11, 17, 0, 3, 0, 19, 4, 3, 8, 16, 11, 10, 21, 13, 34, 7, 12, 14, 52, 11, 0, 3, 0, 19, 4, 42, 16, 6, 10, 13, 52, 22, 11, 4, 6, 3, 35, 56, 3, 4, 33, 0, 3, 0, 19, 4, 52, 22, 11, 4, 6, 23, 6, 9, 27, 25, 10, 21, 56, 3, 8, 38, 0, 3, 0, 4, 17, 0, 90, 3, 33, 4, 51, 57, 38, 0, 13, 34, 7, 12, 14, 52, 11, 91, 0, 3, 0, 4, 3, 30, 4, 4, 12, 10, 49, 15, 4, 6, 19, 38, 3, 35, 56, 3, 4, 33, 0, 3, 0, 4, 23, 4, 4, 10, 3, 0, 9, 7, 18, 13, 52, 22, 11, 4, 6, 0, 3, 0, 4, 3, 9, 10, 3, 11, 5, 6, 78, 0, 3, 0, 4, 3, 6, 7, 25, 4, 10, 13, 52, 22, 11, 4, 6, 93, 3, 0, 9, 7, 0, 3, 0, 4, 3, 22, 9, 40, 10, 37, 88, 21, 3, 0, 5, 15, 0, 3, 0, 5, 8, 8, 17, 0, 23, 9, 8, 0, 36, 31, 3, 98, 16, 10, 6, 67, 38, 0, 3, 0, 5, 15, 91, 0, 3, 0, 4, 3, 6, 7, 25, 4, 10, 56, 52, 22, 11, 4, 6, 0, 3, 0, 4, 3, 8, 16, 11, 10, 20, 32, 7, 17, 55, 3, 0, 9, 7, 0, 3, 0, 19, 4, 34, 7, 12, 14, 52, 11, 23, 19, 7, 25, 4, 10, 56, 29, 7, 14, 0, 3, 0, 4, 28, 7, 12, 25, 10, 20, 32, 7, 17, 0, 3, 0, 5, 15, 18, 3, 0, 9, 7, 3, 12, 7, 16, 22, 19, 0, 3, 0, 19, 4, 17, 3, 6, 19, 9, 11, 25, 13, 52, 22, 11, 4, 6, 3, 9, 10, 92, 0, 3, 0, 19, 4, 17, 3, 22, 5, 21, 3, 0, 5, 15, 0, 10, 3, 19, 5, 16, 10, 4, 0, 3, 0, 19, 4, 17, 67, 55, 13, 52, 22, 11, 4, 6, 18, 3, 5, 6, 19, 46, 21, 17, 10, 0, 3, 0, 19, 4, 17, 3, 33, 4, 78, 0, 3, 0, 19, 4, 17, 3, 33, 4, 76, 10, 0], [3, 0, 9, 7, 18, 3, 0, 4, 11, 80, 34, 5, 8, 24, 0, 3, 0, 19, 4, 17, 69, 67, 24, 55, 20, 43, 13, 9, 8, 21, 17, 10, 18, 3, 8, 4, 7, 14, 20, 43, 13, 9, 8, 34, 5, 5, 25, 10, 0, 3, 0, 19, 4, 17, 28, 7, 44, 24, 21, 57, 49, 15, 4, 6, 19, 38, 92, 0, 3, 0, 7, 11, 28, 4, 28, 7, 6, 54, 20, 3, 30, 9, 12, 15, 0, 3, 0, 9, 7, 20, 10, 25, 24, 48, 62, 0, 3, 0, 5, 8, 8, 17, 0, 23, 32, 4, 4, 6, 9, 4, 0, 13, 3, 30, 9, 12, 15, 3, 9, 10, 3, 11, 5, 6, 66, 71, 3, 25, 9, 14, 10, 0, 3, 0, 6, 3, 9, 10, 23, 27, 33, 17, 18, 3, 12, 5, 16, 14, 0, 3, 0, 5, 16, 28, 9, 43, 3, 11, 5, 6, 73, 37, 0, 3, 0, 5, 15, 53, 0, 3, 0, 7, 11, 28, 4, 3, 22, 5, 3, 5, 16, 6, 10, 9, 14, 4, 0, 3, 0, 4, 11, 20, 10, 25, 24, 0, 3, 0, 5, 8, 8, 17, 0, 3, 19, 35, 4, 17, 0, 37, 3, 9, 10, 21, 5, 39, 5, 12, 14, 18, 28, 4, 6, 0, 3, 0, 5, 16, 28, 9, 43, 39, 7, 6, 54, 20, 39, 5, 12, 14, 0, 3, 0, 5, 16, 3, 11, 4, 24, 21, 23, 6, 7, 17, 50, 10, 9, 14, 4, 0, 3, 0, 5, 15, 53, 0, 3, 0, 9, 7, 18, 3, 0, 4, 11, 23, 9, 22, 19, 24, 0, 3, 0, 19, 4, 17, 86, 3, 11, 5, 6, 3, 25, 11, 5, 32, 90, 21, 57, 0, 3, 0, 4, 17, 0, 3, 0, 59, 40, 20, 11, 3, 9, 14, 4, 7, 0, 3, 0, 5, 15, 53, 0, 3, 0, 19, 17, 57, 11, 0, 6, 51, 3, 6, 7, 25, 4, 20, 3, 11, 7, 26, 0, 3, 0, 5, 16, 28, 9, 43, 3, 30, 4, 4, 12, 45, 6, 6, 46, 18, 59, 40, 3, 15, 5, 8, 4, 3, 4, 11, 46, 22, 17, 3, 12, 7, 6, 46, 0, 3, 0, 3, 11, 7, 26, 0, 3, 0, 9, 7, 18, 3, 0, 4, 11, 53, 0, 3, 0, 19, 4, 17, 86, 3, 11, 5, 6, 28, 7, 44, 21, 3, 11, 7, 26, 0, 3, 0, 19, 4, 17, 28, 7, 44, 24, 21, 59, 40, 92, 0, 3, 0, 4, 10, 0, 20, 3, 11, 7, 26, 0, 3, 0, 5, 15, 4, 3, 35, 0, 3, 0, 28, 9, 43, 3, 6, 16, 27, 25, 51, 50, 0, 3, 0, 5, 16, 81, 39, 16, 14, 14, 12, 4, 55, 51, 8, 3, 6, 24, 14, 17, 45, 33, 10, 18, 3, 12, 9, 10, 6, 4, 11, 21, 49, 15, 4, 3, 15, 16, 10, 9, 27, 0, 3, 0, 5, 15, 53, 0, 3, 0, 19, 4, 3, 12, 24, 13, 15, 21, 13, 9, 8, 45, 14, 8, 5, 5, 15, 18, 29, 12, 26, 24, 13, 15, 3, 22, 4, 6, 50, 6, 5, 13, 9, 8, 45, 14, 10, 0, 3, 0, 19, 4, 3, 22, 7, 40, 13, 15, 3, 4, 7, 54, 20, 3, 25, 9, 10, 10, 18, 3, 6, 16, 8, 11, 24, 3, 35, 13, 3, 15, 16, 10, 9, 27, 0, 3, 0, 12, 4, 4, 26, 28, 4, 43, 0, 3, 15, 17, 3, 12, 5, 40, 10, 0, 3, 0, 28, 9, 43, 28, 7, 25, 4, 51, 68, 89, 13, 3, 30, 9, 12, 15, 3, 9, 10, 3, 5, 40, 8, 0, 3, 0, 19, 4, 53, 0, 3, 0, 9, 7, 18, 3, 0, 4, 11, 39, 12, 5, 10, 24, 13, 9, 8, 3, 4, 17, 4, 10, 0, 3, 0, 19, 4, 17, 3, 6, 8, 9, 24, 21, 23, 6, 7, 17, 20, 32, 7, 25, 4, 0, 64, 13, 3, 15, 16, 10, 9, 27, 31, 49, 30, 6, 18, 49, 5, 6, 19, 38, 0, 3, 0, 19, 4, 17, 3, 30, 4, 12, 6, 28, 33, 15, 18, 39, 5, 97, 17, 0, 3, 0, 19, 4, 17, 3, 14, 8, 9, 30, 6, 24, 58, 30, 21, 23, 12, 4, 4, 26, 0, 3, 0, 19, 4, 17, 69, 20, 3, 11, 9, 27, 4, 3, 14, 8, 4, 7, 15, 0, 3, 0, 19, 4, 17, 3, 14, 8, 4, 7, 15, 24, 61, 41, 80, 50, 20, 3, 30, 9, 12, 15, 0, 3, 0, 19, 4, 17, 80, 13, 23, 6, 33, 10, 0, 3, 0, 19, 4, 17, 69, 20, 14, 40, 44, 16, 8, 4, 10, 18, 52, 14, 4, 76, 10, 0, 3, 0, 19, 4, 17, 3, 12, 7, 16, 22, 19, 24, 18, 23, 7, 11, 22, 0, 3, 0, 19, 4, 17, 80, 3, 11, 5, 6, 34, 5, 8, 24, 20, 6, 20, 43, 0, 3, 0, 19, 4, 11, 41, 28, 5, 25, 4, 68, 0, 41, 79, 3, 0, 5, 15, 23, 15, 9, 12, 38, 20, 6, 13, 15, 0, 3, 0, 19, 4, 72, 24, 42, 7, 12, 4, 0, 3, 0, 19, 4, 69, 3, 14, 33, 25, 39, 9, 8, 27, 12, 4, 10, 3, 16, 11, 14, 46, 48, 3, 4, 17, 4, 10, 0, 3, 0, 9, 14, 51, 3, 4, 11, 98, 5, 17, 13, 3, 30, 9, 12, 15, 0, 3, 0, 9, 7, 20, 10, 25, 24, 0, 3, 0, 5, 6, 3, 8, 4, 7, 43, 17, 0, 3, 0, 6, 31, 23, 27, 33, 17, 18, 3, 12, 5, 16, 14, 0, 3, 0, 86, 3, 11, 5, 6, 73, 37, 0, 3, 0, 5, 15, 53, 0, 3, 0, 7, 11, 28, 4, 28, 7, 6, 54, 37, 0, 3, 0, 4, 11, 20, 10, 25, 24, 0, 3, 0, 5, 0, 51, 81, 0, 6, 0, 3, 0, 6, 3, 9, 10, 3, 11, 5, 6, 66, 71, 3, 25, 9, 14, 10, 0, 3, 0, 8, 16, 10, 6, 3, 15, 4, 0, 51, 28, 5, 16, 12, 14, 3, 11, 5, 6, 73, 37, 0, 3, 0, 5, 15, 53, 0, 3, 0, 7, 11, 28, 4, 3, 22, 5, 3, 5, 16, 6, 10, 9, 14, 4, 0, 3, 0, 9, 7, 20, 10, 25, 24, 0, 3, 0, 4, 10, 0, 51, 81, 0, 3, 0, 6, 3, 9, 10, 23, 16, 11, 11, 17, 18, 3, 14, 8, 17, 0, 3, 0, 5, 16, 81, 67, 50, 13, 3, 22, 33, 14, 4, 11, 0, 3, 0, 5, 15, 4, 3, 35, 0, 3, 12, 4, 6, 0, 10, 3, 22, 5, 0, 3, 0, 5, 15, 53, 0, 3, 0, 9, 7, 18, 3, 0, 4, 11, 3, 98, 16, 15, 26, 24, 3, 5, 16, 6, 58, 13, 9, 8, 45, 14, 10, 0, 3, 0, 19, 4, 17, 3, 22, 8, 7, 47, 47, 24, 13, 9, 8, 39, 5, 7, 6, 10, 18, 23, 19, 5, 4, 10, 0, 3, 0, 19, 4, 17, 3, 8, 7, 11, 21, 13, 57, 5, 8, 0, 3, 0, 19, 7, 11, 25, 51, 66, 13, 3, 11, 7, 26, 0, 3, 0, 5, 15, 0, 3, 0, 6, 31, 92, 0, 3, 0, 19, 4, 17, 53, 0, 3, 0, 5, 16, 0, 8, 4, 28, 4, 12, 27, 5, 15, 4, 0, 3, 15, 17, 3, 12, 5, 40, 10, 0, 3, 0, 15, 3, 22, 12, 7, 14, 51, 69, 92, 0, 3, 0, 5, 15, 53, 0, 3, 0, 19, 4, 3, 30, 5, 43, 5, 32, 24, 13, 15, 3, 5, 16, 6, 10, 9, 14, 4, 0, 3, 0, 19, 4, 3, 30, 4, 12, 6, 3, 6, 9, 8, 24, 18, 49, 8, 4, 0, 3, 0, 19, 4, 28, 9, 10, 19, 24, 36, 69, 3, 6, 7, 25, 4, 11, 20, 3, 11, 7, 26, 21, 5, 0], [3, 0, 5, 47, 31, 49, 3, 4, 70, 27, 9, 6, 24, 0, 3, 0, 4, 69, 45, 4, 11, 72, 38, 66, 32, 33, 14, 21, 13, 77, 65, 66, 49, 3, 12, 35, 22, 0, 3, 0, 6, 31, 3, 30, 9, 11, 7, 43, 17, 48, 4, 0, 3, 0, 4, 31, 20, 47, 5, 16, 6, 21, 3, 22, 5, 3, 35, 20, 3, 8, 4, 7, 12, 20, 14, 40, 44, 16, 8, 4, 0, 3, 0, 4, 31, 3, 22, 5, 38, 21, 13, 3, 98, 16, 11, 22, 12, 4, 55, 56, 42, 33, 4, 44, 10, 0, 3, 0, 4, 69, 45, 4, 11, 3, 9, 15, 7, 22, 9, 11, 38, 37, 66, 28, 4, 4, 25, 10, 0, 3, 0, 19, 4, 3, 6, 8, 4, 4, 10, 0, 13, 20, 11, 9, 15, 7, 12, 10, 0, 18, 13, 3, 22, 8, 4, 7, 6, 77, 23, 27, 33, 17, 39, 7, 40, 10, 0, 3, 0, 4, 42, 7, 27, 25, 24, 56, 34, 7, 22, 0, 42, 16, 6, 3, 35, 56, 59, 6, 18, 3, 22, 5, 6, 50, 13, 39, 33, 0, 3, 0, 9, 10, 3, 14, 7, 14, 3, 14, 8, 5, 40, 13, 15, 20, 43, 13, 28, 7, 17, 21, 13, 3, 24, 22, 4, 58, 13, 3, 98, 16, 11, 22, 12, 4, 0, 28, 19, 46, 4, 13, 8, 4, 31, 20, 3, 30, 7, 25, 4, 21, 9, 12, 4, 6, 61, 20, 43, 13, 20, 11, 9, 15, 7, 12, 10, 87, 3, 16, 10, 4, 0, 3, 0, 5, 5, 25, 3, 0, 7, 14, 14, 17, 0, 3, 0, 19, 7, 6, 0, 10, 61, 0, 3, 0, 5, 47, 20, 10, 25, 24, 0, 42, 5, 9, 44, 38, 20, 6, 13, 21, 9, 12, 4, 6, 0, 3, 0, 19, 7, 6, 0, 10, 20, 21, 9, 12, 4, 6, 0, 3, 0, 5, 47, 0, 56, 3, 14, 7, 14, 3, 8, 4, 26, 12, 9, 24, 0, 3, 0, 5, 47, 87, 11, 0, 6, 45, 12, 9, 4, 40, 37, 0, 3, 0, 3, 8, 4, 7, 12, 3, 30, 7, 25, 4, 21, 9, 12, 4, 6, 52, 14, 4, 3, 4, 10, 26, 4, 27, 9, 7, 43, 17, 66, 20, 11, 9, 15, 7, 12, 10, 0, 3, 0, 4, 31, 49, 3, 4, 70, 27, 9, 6, 24, 0, 29, 31, 3, 8, 4, 7, 14, 17, 21, 23, 6, 33, 6, 3, 4, 70, 26, 12, 5, 8, 38, 0, 3, 0, 4, 87, 11, 0, 6, 28, 7, 9, 6, 0], [3, 0, 11, 27, 4, 68, 35, 20, 74, 0, 13, 8, 4, 31, 20, 71, 85, 3, 11, 7, 15, 24, 3, 0, 9, 12, 17, 0, 3, 0, 19, 4, 3, 12, 5, 40, 14, 21, 67, 55, 48, 21, 17, 10, 0, 3, 0, 11, 4, 65, 0, 3, 0, 9, 12, 17, 28, 7, 44, 24, 21, 50, 27, 12, 16, 14, 4, 48, 3, 6, 24, 14, 17, 45, 33, 50, 48, 67, 6, 9, 15, 4, 0, 3, 0, 19, 4, 42, 16, 6, 48, 3, 6, 24, 14, 17, 45, 33, 20, 6, 13, 3, 6, 4, 7, 42, 33, 6, 17, 55, 48, 57, 43, 10, 0, 3, 0, 10, 3, 0, 9, 12, 17, 67, 24, 0, 36, 79, 48, 34, 8, 5, 6, 19, 46, 3, 0, 5, 15, 67, 38, 55, 56, 21, 17, 39, 33, 10, 0, 3, 0, 5, 15, 31, 52, 25, 38, 56, 39, 33, 10, 3, 22, 5, 3, 60, 3, 30, 7, 10, 6, 0, 3, 0, 9, 12, 17, 28, 7, 44, 24, 21, 3, 98, 5, 9, 11, 3, 0, 5, 15, 0, 49, 36, 21, 5, 25, 48, 3, 6, 24, 14, 17, 45, 33, 18, 28, 4, 44, 21, 67, 55, 82, 0, 3, 0, 19, 4, 17, 67, 24, 21, 22, 4, 6, 19, 46, 0, 3, 12, 7, 16, 22, 19, 38, 18, 59, 75, 38, 92, 0, 3, 0, 16, 6, 13, 11, 0, 3, 0, 9, 12, 17, 0, 10, 3, 6, 24, 14, 17, 45, 33, 3, 30, 4, 43, 57, 32, 11, 0, 3, 0, 19, 4, 11, 3, 0, 9, 12, 17, 42, 9, 27, 25, 24, 37, 68, 0, 36, 79, 61, 37, 10, 3, 30, 38, 46, 31, 34, 8, 5, 25, 4, 11, 0, 3, 0, 9, 12, 17, 31, 23, 7, 14, 18, 39, 8, 9, 24, 0, 3, 0, 5, 15, 79, 48, 3, 6, 4, 33, 10, 18, 3, 30, 4, 12, 6, 49, 8, 8, 17, 0, 3, 0, 4, 29, 12, 26, 24, 48, 3, 30, 9, 70, 13, 3, 6, 24, 14, 17, 45, 33, 0, 10, 34, 8, 5, 25, 4, 11, 3, 30, 38, 46, 55, 20, 71, 34, 7, 11, 14, 7, 22, 4, 0, 3, 0, 5, 32, 0, 3, 0, 9, 12, 17, 0, 10, 3, 6, 24, 14, 17, 45, 33, 31, 20, 43, 45, 6, 6, 46, 0, 18, 41, 87, 67, 21, 22, 4, 6, 19, 46, 20, 22, 7, 9, 11, 0, 3, 0, 19, 4, 17, 3, 12, 4, 33, 11, 24, 61, 89, 41, 50, 27, 12, 16, 14, 4, 3, 4, 7, 54, 3, 5, 6, 19, 46, 18, 29, 12, 26, 3, 4, 7, 54, 3, 5, 6, 19, 46, 0, 41, 81, 59, 40, 3, 15, 5, 8, 4, 92, 18, 3, 30, 9, 70, 20, 11, 17, 42, 8, 5, 47, 12, 4, 15, 0], [3, 0, 11, 27, 4, 68, 35, 20, 74, 0, 13, 8, 4, 3, 12, 9, 40, 14, 20, 71, 34, 5, 17, 3, 11, 7, 15, 24, 3, 0, 7, 27, 25, 0, 3, 0, 11, 4, 65, 0, 29, 28, 7, 44, 24, 21, 3, 22, 5, 3, 5, 16, 6, 18, 3, 4, 70, 26, 12, 5, 8, 4, 13, 3, 5, 16, 6, 10, 9, 14, 4, 28, 5, 8, 12, 14, 0, 3, 0, 5, 29, 42, 16, 6, 3, 35, 56, 59, 6, 18, 23, 19, 5, 4, 10, 0, 18, 28, 4, 44, 3, 5, 16, 6, 10, 9, 14, 4, 0, 3, 0, 4, 79, 20, 23, 6, 8, 4, 7, 15, 18, 29, 31, 49, 3, 4, 70, 27, 9, 6, 24, 0, 3, 0, 4, 28, 7, 44, 24, 21, 3, 6, 7, 25, 4, 20, 39, 12, 5, 10, 46, 72, 0, 49, 29, 3, 8, 7, 11, 68, 21, 37, 0, 3, 0, 19, 4, 11, 29, 3, 22, 5, 6, 13, 8, 4, 0, 29, 79, 20, 71, 3, 30, 9, 10, 19, 38, 34, 5, 7, 6, 50, 13, 23, 6, 8, 4, 7, 15, 0, 3, 0, 4, 53, 21, 82, 10, 4, 12, 30, 0, 3, 0, 19, 0, 3, 0, 28, 7, 44, 21, 3, 22, 5, 3, 30, 9, 10, 19, 38, 0, 3, 0, 16, 6, 29, 86, 11, 0, 6, 3, 25, 11, 5, 32, 3, 19, 5, 32, 21, 57, 37, 0, 3, 0, 9, 10, 3, 15, 16, 15, 39, 7, 15, 4, 3, 5, 40, 8, 0, 18, 36, 53, 3, 0, 9, 0, 3, 0, 7, 27, 25, 0, 3, 0, 8, 4, 51, 3, 8, 4, 7, 14, 17, 21, 3, 22, 5, 3, 30, 9, 10, 19, 38, 0, 3, 0, 7, 27, 25, 31, 49, 78, 0, 18, 29, 53, 3, 0, 4, 10, 0, 3, 0, 20, 15, 3, 8, 4, 7, 14, 17, 0, 3, 0, 12, 4, 7, 10, 4, 23, 4, 11, 14, 3, 15, 4, 3, 5, 16, 6, 0, 3, 0, 16, 15, 0, 3, 0, 28, 7, 44, 21, 39, 7, 6, 54, 20, 77, 3, 30, 9, 10, 19, 50, 13, 23, 6, 8, 4, 7, 15, 0, 3, 0, 9, 10, 3, 15, 16, 15, 23, 15, 9, 12, 24, 0, 18, 13, 11, 36, 23, 4, 44, 3, 0, 7, 27, 25, 3, 5, 16, 6, 50, 13, 71, 34, 5, 7, 6, 0, 3, 0, 4, 69, 20, 11, 20, 15, 7, 97, 38, 74, 3, 30, 9, 10, 19, 38, 50, 13, 23, 6, 8, 4, 7, 15, 18, 49, 35, 0, 29, 39, 7, 16, 22, 19, 6, 13, 77, 22, 4, 10, 6, 3, 30, 9, 10, 19, 3, 4, 40, 8, 0], [3, 0, 11, 4, 65, 0, 20, 71, 34, 5, 17, 3, 11, 7, 15, 24, 3, 0, 7, 27, 25, 31, 28, 7, 12, 25, 38, 50, 13, 66, 4, 10, 6, 0, 3, 0, 6, 31, 3, 22, 4, 6, 6, 38, 3, 14, 33, 25, 0, 49, 29, 42, 7, 16, 10, 24, 18, 72, 24, 3, 33, 5, 16, 11, 14, 0, 3, 0, 4, 79, 20, 3, 12, 9, 22, 19, 6, 50, 13, 3, 14, 9, 10, 6, 7, 11, 27, 4, 0, 49, 29, 28, 4, 44, 21, 32, 33, 14, 10, 37, 0, 3, 0, 19, 4, 11, 29, 3, 8, 4, 7, 54, 24, 37, 0, 29, 79, 20, 23, 15, 7, 43, 39, 5, 6, 6, 7, 22, 4, 0, 3, 0, 4, 31, 39, 16, 8, 9, 5, 16, 10, 0, 49, 29, 3, 25, 11, 5, 27, 25, 24, 3, 35, 13, 57, 5, 8, 0, 3, 0, 16, 14, 14, 4, 11, 12, 17, 0, 20, 11, 3, 5, 12, 14, 28, 5, 15, 7, 11, 3, 5, 26, 4, 11, 24, 13, 57, 5, 8, 0, 3, 0, 19, 4, 31, 3, 30, 8, 9, 22, 19, 6, 4, 11, 24, 18, 21, 12, 14, 82, 21, 3, 22, 5, 20, 32, 7, 17, 0, 3, 0, 7, 27, 25, 31, 23, 27, 33, 24, 0, 49, 29, 3, 8, 7, 11, 20, 32, 7, 17, 88, 50, 6, 5, 13, 66, 4, 10, 6, 0, 3, 0, 4, 72, 24, 45, 19, 9, 11, 14, 82, 0, 18, 29, 87, 23, 6, 9, 43, 23, 4, 4, 13, 3, 12, 9, 22, 19, 6, 0, 3, 0, 7, 27, 25, 31, 3, 8, 16, 11, 11, 38, 3, 6, 19, 8, 5, 16, 22, 19, 13, 3, 14, 33, 25, 0, 64, 29, 87, 11, 0, 6, 3, 30, 9, 11, 14, 56, 28, 7, 17, 3, 5, 16, 6, 0, 3, 0, 4, 31, 49, 3, 30, 8, 9, 22, 19, 6, 4, 11, 24, 0, 29, 23, 6, 33, 6, 24, 21, 39, 8, 17, 0, 3, 0, 16, 14, 14, 4, 11, 12, 17, 0, 49, 15, 4, 6, 19, 38, 3, 22, 8, 7, 47, 47, 24, 82, 93, 45, 19, 9, 11, 14, 18, 3, 14, 8, 7, 22, 22, 24, 82, 20, 32, 7, 17, 0, 3, 0, 11, 13, 3, 14, 33, 25, 11, 4, 10, 10, 0, 3, 0, 7, 27, 25, 3, 11, 4, 40, 8, 3, 8, 4, 6, 16, 8, 11, 24, 0], [3, 0, 11, 27, 4, 68, 35, 20, 74, 0, 13, 8, 4, 31, 20, 71, 85, 3, 11, 7, 15, 24, 3, 0, 9, 12, 17, 0, 3, 0, 19, 4, 3, 12, 5, 40, 14, 21, 67, 20, 6, 13, 42, 33, 25, 55, 48, 76, 10, 0, 3, 0, 19, 4, 17, 28, 5, 16, 12, 14, 3, 8, 16, 11, 18, 3, 98, 16, 15, 26, 18, 3, 12, 7, 16, 22, 19, 21, 22, 4, 6, 19, 46, 0, 3, 0, 11, 4, 65, 0, 41, 79, 20, 77, 23, 12, 9, 14, 4, 18, 41, 20, 43, 28, 7, 44, 24, 21, 3, 22, 5, 3, 35, 37, 0, 3, 0, 9, 12, 17, 39, 12, 9, 15, 47, 24, 68, 13, 3, 12, 7, 14, 14, 46, 18, 23, 12, 9, 14, 57, 32, 11, 13, 23, 12, 9, 14, 4, 0, 3, 0, 6, 31, 49, 3, 15, 16, 54, 92, 0, 3, 0, 16, 6, 13, 11, 0, 36, 79, 20, 42, 5, 10, 6, 20, 6, 13, 34, 5, 6, 6, 5, 15, 58, 13, 23, 12, 9, 14, 4, 0, 3, 0, 19, 4, 3, 6, 8, 9, 24, 21, 23, 6, 5, 26, 48, 10, 4, 12, 30, 0, 64, 36, 87, 11, 0, 6, 18, 36, 3, 19, 9, 6, 13, 42, 5, 10, 6, 0, 3, 0, 6, 3, 19, 16, 8, 6, 20, 3, 12, 5, 6, 18, 36, 3, 30, 4, 12, 6, 3, 60, 3, 16, 11, 27, 5, 15, 30, 5, 8, 6, 7, 47, 12, 4, 0, 3, 0, 46, 76, 10, 3, 6, 8, 9, 24, 21, 29, 12, 26, 48, 0, 64, 36, 31, 21, 5, 3, 19, 16, 8, 6, 21, 67, 20, 11, 17, 15, 5, 8, 4, 0, 3, 0, 19, 4, 69, 21, 3, 22, 5, 21, 13, 3, 19, 5, 10, 26, 9, 6, 7, 12, 18, 3, 22, 4, 6, 20, 39, 7, 10, 6, 3, 35, 48, 3, 33, 15, 0, 3, 0, 9, 12, 17, 31, 3, 60, 23, 7, 14, 61, 36, 87, 11, 0, 6, 67, 55, 48, 76, 10, 66, 20, 3, 12, 35, 22, 74, 0, 3, 0, 19, 4, 3, 12, 4, 33, 11, 24, 21, 45, 3, 15, 5, 8, 4, 39, 33, 4, 83, 89, 67, 38, 20, 6, 13, 42, 33, 25, 0], [3, 0, 11, 4, 65, 0, 3, 0, 7, 27, 25, 31, 28, 7, 12, 25, 38, 57, 32, 11, 13, 23, 6, 8, 4, 4, 6, 21, 67, 0, 3, 0, 60, 6, 19, 38, 31, 49, 50, 6, 46, 4, 10, 6, 38, 50, 21, 32, 11, 0, 3, 0, 4, 79, 20, 52, 11, 23, 9, 6, 6, 38, 3, 35, 20, 45, 11, 54, 0, 3, 0, 7, 27, 25, 3, 6, 19, 5, 16, 22, 19, 6, 37, 28, 5, 16, 12, 14, 45, 3, 11, 9, 27, 4, 21, 23, 7, 17, 29, 43, 5, 18, 29, 28, 4, 44, 3, 5, 40, 8, 21, 3, 6, 7, 12, 25, 21, 82, 0, 3, 0, 5, 5, 14, 3, 15, 5, 8, 11, 38, 0, 53, 3, 0, 7, 27, 25, 0, 3, 0, 19, 4, 52, 11, 3, 22, 7, 40, 20, 28, 33, 15, 28, 4, 12, 27, 5, 15, 4, 21, 3, 0, 7, 27, 25, 18, 23, 15, 9, 12, 24, 0, 3, 0, 4, 53, 29, 69, 20, 42, 8, 4, 10, 4, 44, 66, 3, 0, 7, 27, 25, 18, 59, 11, 14, 24, 82, 20, 34, 5, 70, 0, 3, 0, 6, 31, 28, 8, 7, 26, 26, 24, 50, 23, 19, 9, 11, 17, 42, 7, 26, 46, 18, 69, 20, 77, 34, 5, 32, 3, 35, 21, 26, 0, 3, 0, 7, 27, 25, 3, 6, 19, 5, 16, 22, 19, 6, 37, 72, 24, 3, 8, 4, 7, 43, 17, 92, 18, 29, 45, 22, 7, 11, 21, 3, 5, 26, 4, 11, 37, 0, 3, 0, 11, 10, 9, 14, 4, 31, 20, 21, 17, 3, 8, 5, 47, 5, 6, 0, 3, 0, 7, 27, 25, 3, 12, 5, 40, 14, 3, 8, 5, 47, 5, 6, 10, 0, 49, 29, 3, 6, 8, 16, 10, 6, 24, 13, 52, 11, 18, 3, 6, 19, 7, 11, 25, 24, 82, 66, 13, 21, 17, 0, 3, 0, 16, 6, 20, 10, 49, 35, 20, 10, 29, 3, 6, 19, 7, 11, 25, 24, 82, 0, 13, 52, 11, 3, 22, 8, 7, 47, 47, 24, 3, 0, 7, 27, 25, 18, 3, 8, 7, 11, 20, 32, 7, 17, 0, 3, 0, 7, 27, 25, 31, 23, 27, 33, 24, 18, 3, 6, 8, 9, 24, 21, 3, 4, 10, 27, 7, 26, 4, 0, 64, 37, 31, 21, 5, 3, 12, 7, 6, 4, 0, 3, 0, 7, 27, 25, 69, 3, 6, 8, 16, 10, 6, 24, 13, 52, 11, 21, 5, 3, 4, 7, 10, 9, 12, 17, 18, 29, 3, 11, 4, 40, 8, 23, 19, 5, 16, 12, 14, 59, 40, 3, 6, 7, 25, 4, 11, 13, 42, 8, 4, 10, 4, 44, 0, 3, 0, 6, 31, 20, 3, 15, 9, 10, 6, 7, 25, 4, 61, 3, 0, 7, 27, 25, 28, 5, 16, 12, 14, 3, 8, 4, 22, 8, 4, 6, 66, 4, 40, 8, 0], [3, 0, 11, 27, 4, 13, 8, 4, 31, 20, 3, 12, 35, 4, 12, 17, 45, 33, 0, 3, 0, 4, 28, 7, 44, 24, 21, 20, 27, 6, 28, 9, 12, 14, 64, 29, 69, 3, 11, 5, 3, 35, 4, 21, 67, 55, 0, 3, 0, 11, 4, 65, 29, 29, 33, 14, 20, 3, 11, 5, 9, 10, 4, 50, 13, 28, 5, 5, 14, 10, 0, 3, 0, 19, 4, 11, 29, 3, 22, 5, 6, 13, 8, 4, 29, 79, 20, 3, 8, 7, 47, 47, 9, 6, 3, 19, 5, 26, 26, 38, 3, 33, 5, 16, 11, 14, 0, 3, 0, 19, 4, 45, 33, 18, 13, 3, 8, 7, 47, 47, 9, 6, 23, 6, 33, 6, 24, 21, 20, 27, 6, 28, 9, 12, 14, 0, 3, 98, 16, 15, 26, 38, 18, 3, 8, 16, 11, 11, 38, 3, 33, 5, 16, 11, 14, 13, 28, 5, 5, 14, 10, 0, 3, 0, 19, 4, 17, 3, 98, 16, 15, 26, 24, 18, 3, 54, 7, 10, 24, 3, 4, 7, 54, 3, 5, 6, 19, 46, 3, 33, 5, 16, 11, 14, 0, 3, 16, 44, 9, 12, 41, 34, 5, 6, 19, 3, 22, 5, 6, 3, 6, 9, 8, 24, 0, 3, 0, 19, 4, 45, 33, 18, 13, 3, 8, 7, 47, 47, 9, 6, 80, 3, 11, 5, 3, 12, 35, 22, 46, 3, 12, 35, 4, 12, 17, 0, 18, 41, 67, 24, 21, 22, 4, 6, 19, 46, 3, 4, 60, 65, 50, 13, 28, 5, 5, 14, 10, 0], [3, 0, 6, 31, 20, 34, 8, 9, 22, 19, 6, 18, 3, 54, 4, 46, 83, 65, 0, 3, 0, 7, 43, 17, 0, 28, 19, 5, 31, 3, 6, 19, 8, 4, 4, 3, 17, 4, 33, 10, 3, 5, 12, 14, 0, 31, 67, 38, 55, 48, 76, 10, 50, 13, 42, 33, 25, 0, 3, 0, 19, 4, 31, 3, 8, 16, 11, 11, 38, 3, 33, 5, 16, 11, 14, 18, 59, 75, 38, 3, 12, 5, 6, 10, 58, 92, 0, 3, 0, 16, 14, 14, 4, 11, 12, 17, 0, 20, 3, 12, 5, 16, 14, 3, 11, 5, 9, 10, 4, 52, 14, 4, 3, 0, 7, 43, 17, 3, 98, 16, 15, 26, 50, 23, 19, 5, 27, 25, 0, 3, 0, 60, 35, 4, 72, 24, 3, 33, 5, 16, 11, 14, 21, 23, 4, 4, 90, 69, 39, 7, 16, 10, 24, 13, 3, 12, 5, 16, 14, 3, 11, 5, 9, 10, 4, 0, 3, 0, 6, 31, 13, 49, 16, 11, 14, 58, 20, 77, 34, 7, 43, 5, 35, 42, 5, 26, 26, 38, 0, 3, 0, 43, 13, 3, 54, 9, 12, 14, 8, 4, 11, 80, 23, 27, 33, 24, 18, 3, 8, 7, 11, 20, 32, 7, 17, 0, 3, 0, 7, 43, 17, 3, 30, 4, 12, 6, 20, 28, 7, 40, 58, 3, 30, 4, 33, 39, 5, 15, 4, 3, 5, 40, 8, 48, 0, 3, 0, 19, 4, 28, 7, 44, 24, 21, 3, 22, 7, 9, 11, 39, 5, 16, 8, 7, 22, 4, 18, 3, 30, 9, 22, 19, 6, 3, 6, 19, 9, 10, 3, 30, 4, 33, 0, 64, 37, 23, 4, 4, 15, 24, 21, 5, 59, 8, 14, 66, 48, 0, 3, 0, 19, 4, 39, 12, 5, 10, 24, 48, 3, 4, 17, 4, 10, 0, 21, 5, 25, 20, 3, 14, 4, 4, 26, 34, 8, 4, 7, 6, 19, 18, 3, 5, 26, 4, 11, 24, 13, 15, 20, 22, 7, 9, 11, 0, 3, 0, 9, 6, 19, 20, 34, 16, 8, 10, 6, 58, 3, 14, 4, 6, 46, 15, 9, 11, 7, 6, 9, 35, 0, 3, 0, 7, 43, 17, 23, 6, 4, 26, 26, 24, 66, 32, 33, 14, 0, 3, 0, 43, 48, 76, 10, 72, 24, 20, 6, 48, 55, 20, 14, 15, 9, 8, 7, 6, 9, 35, 0, 3, 0, 19, 4, 21, 5, 25, 20, 11, 5, 6, 19, 46, 23, 6, 4, 26, 66, 32, 33, 14, 18, 42, 5, 26, 26, 24, 13, 77, 34, 7, 43, 5, 35, 55, 48, 3, 30, 5, 5, 6, 0, 3, 0, 60, 35, 4, 3, 54, 4, 46, 24, 66, 3, 0, 7, 43, 17, 0, 3, 0, 19, 4, 69, 3, 22, 7, 9, 11, 24, 39, 5, 16, 8, 7, 22, 4, 18, 23, 6, 5, 26, 26, 24, 13, 3, 30, 4, 33, 55, 48, 3, 14, 4, 6, 46, 15, 9, 11, 7, 6, 9, 35, 0, 3, 0, 8, 5, 15, 13, 11, 3, 35, 0, 3, 0, 7, 43, 17, 31, 3, 25, 11, 5, 32, 11, 21, 45, 34, 8, 7, 40, 18, 39, 5, 16, 8, 7, 22, 4, 5, 16, 10, 0]]\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train.head())\n",
        "# print(val.head())\n",
        "# print(test.head())"
      ],
      "metadata": {
        "id": "shh1d6t0kNOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show keras-preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCKJWX7dtbYK",
        "outputId": "07dcdfd6-b095-4ec8-eeb3-a8253d47c783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Keras-Preprocessing\n",
            "Version: 1.1.2\n",
            "Summary: Easy data preprocessing and data augmentation for deep learning models\n",
            "Home-page: https://github.com/keras-team/keras-preprocessing\n",
            "Author: Keras Team\n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, six\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "qSfvtlqdtdwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "# Get max sequence length\n",
        "max_len = max(len(t) for t in train_tokens + val_tokens) + 1\n",
        "\n",
        "all_train_tokens = [token for batch in train_tokens for token in batch]\n",
        "all_val_tokens = [token for batch in val_tokens for token in batch]\n",
        "\n",
        "del train_tokens, val_tokens #ram\n",
        "\n",
        "# Pad sequences\n",
        "pad_train_tokens = pad_sequences(all_train_tokens, maxlen=max_len)\n",
        "pad_val_tokens = pad_sequences(all_val_tokens, maxlen=max_len)\n",
        "\n",
        "input_seqs = pad_train_tokens[:, :-1]\n",
        "target_seqs = pad_train_tokens[:, 1:]\n",
        "\n",
        "del pad_train_tokens #rem\n",
        "\n",
        "# Convert to tensors\n",
        "input_tensors = torch.tensor(input_seqs)\n",
        "target_tensors = torch.tensor(target_seqs)\n",
        "train_data = TensorDataset(input_tensors, target_tensors)\n",
        "val_data = TensorDataset(torch.tensor(pad_val_tokens))\n",
        "print(train_data[0][0].shape)\n",
        "del input_seqs, target_seqs, input_tensors, target_tensors, pad_val_tokens"
      ],
      "metadata": {
        "id": "DY6-fosLoHN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eba33b5-a4c9-40d1-b993-5dc704e81a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([99])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZWk2UFLvcvs",
        "outputId": "a17a1fb2-a196-434f-d298-b370bad51c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([66,  3,  4, 60, 35,  4, 21, 45, 23,  7, 30,  4,  0,  3,  0,  7, 14, 12,\n",
            "        17,  0, 13,  3, 30,  9,  8,  4, 23, 26,  8,  4,  7, 14, 18, 52, 11, 17,\n",
            "        42,  4,  5, 26, 12,  4,  3, 12,  5, 10,  6, 13,  9,  8,  3, 19,  5, 15,\n",
            "         4, 10,  0,  3,  0,  9, 15, 15, 17, 18, 56, 62, 15, 17, 80, 23,  7, 14,\n",
            "         0, 64, 41,  3, 25, 11,  4, 32, 41, 69,  3,  4,  7, 54,  3,  5,  6, 19,\n",
            "        46, 21,  3, 12,  4,  7, 11,  3, 35], dtype=torch.int32), tensor([ 3,  4, 60, 35,  4, 21, 45, 23,  7, 30,  4,  0,  3,  0,  7, 14, 12, 17,\n",
            "         0, 13,  3, 30,  9,  8,  4, 23, 26,  8,  4,  7, 14, 18, 52, 11, 17, 42,\n",
            "         4,  5, 26, 12,  4,  3, 12,  5, 10,  6, 13,  9,  8,  3, 19,  5, 15,  4,\n",
            "        10,  0,  3,  0,  9, 15, 15, 17, 18, 56, 62, 15, 17, 80, 23,  7, 14,  0,\n",
            "        64, 41,  3, 25, 11,  4, 32, 41, 69,  3,  4,  7, 54,  3,  5,  6, 19, 46,\n",
            "        21,  3, 12,  4,  7, 11,  3, 35,  0], dtype=torch.int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "KtMFIPF7xJ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer model"
      ],
      "metadata": {
        "id": "PDPjSkWjr46Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    '''\n",
        "    Scaled dot-product attention mechanism.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, dropout):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, scale=None, attn_mask=None):\n",
        "        print(query.shape, key.shape, value.shape)\n",
        "        # Scale dot product scores\n",
        "        if scale is None:\n",
        "            scale = 1 / (key.size(-1) ** 0.5)\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) * scale\n",
        "        print(\"Scores shape:\", scores.shape)\n",
        "\n",
        "        # Apply attention mask\n",
        "        if attn_mask is not None:\n",
        "            scores = scores.masked_fill(attn_mask==0, -1e9)\n",
        "            print(\"Scores shape after mask:\", scores.shape)\n",
        "\n",
        "        # Normalize with softmax\n",
        "        attn_probs = nn.Softmax(dim=-1)(scores)\n",
        "\n",
        "        # Apply dropout\n",
        "        attn_probs = self.dropout(attn_probs)\n",
        "\n",
        "        # Multiply with value vectors\n",
        "        context = torch.matmul(attn_probs, value)\n",
        "\n",
        "        return context"
      ],
      "metadata": {
        "id": "cpw29zCbk0ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim, hidden_dim, dropout):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.linear1 = nn.Linear(embed_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, embed_dim)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.linear2(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "2-w2aY9akumN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim, num_heads, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        self.attention = ScaledDotProductAttention(dropout)\n",
        "\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, query, key, value, attn_mask):\n",
        "\n",
        "        # Retain shape after projection\n",
        "        query = self.q_proj(query)\n",
        "        key = self.k_proj(key)\n",
        "        value = self.v_proj(value)\n",
        "\n",
        "        # Split heads by slicing\n",
        "        head_dim = self.embed_dim // self.num_heads\n",
        "        q_slices = [query[:,:,i*head_dim:(i+1)*head_dim] for i in range(self.num_heads)]\n",
        "        k_slices = [key[:,:,i*head_dim:(i+1)*head_dim] for i in range(self.num_heads)]\n",
        "        v_slices = [value[:,:,i*head_dim:(i+1)*head_dim] for i in range(self.num_heads)]\n",
        "        print(q_slices[0].shape)\n",
        "\n",
        "        # Attention\n",
        "        scale = self.head_dim ** -0.5\n",
        "        outputs = [self.attention(q, k, v, scale, attn_mask) for q, k, v in zip(q_slices, k_slices, v_slices)]\n",
        "\n",
        "        # Recombine heads\n",
        "        output = torch.cat(outputs, dim=-1)\n",
        "\n",
        "        attn_out = self.out_proj(output)\n",
        "\n",
        "        return attn_out"
      ],
      "metadata": {
        "id": "_imMQlsj5eGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class MultiHeadedAttention(nn.Module):\n",
        "\n",
        "#     def __init__(self, embed_dim, num_heads, dropout):\n",
        "\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.embed_dim = embed_dim\n",
        "#         self.num_heads = num_heads\n",
        "#         self.head_dim = embed_dim // num_heads\n",
        "\n",
        "#         self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "#         self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
        "#         self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "#         self.attention = ScaledDotProductAttention(dropout)\n",
        "\n",
        "#         self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # def forward(self, query, key, value, attn_mask):\n",
        "\n",
        "    #     # Split into heads\n",
        "    #     batch_size, seq_len, embed_dim = query.size()\n",
        "\n",
        "    #     query = self.q_proj(query).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "    #     key = self.k_proj(key).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "    #     value = self.v_proj(value).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "    # #     print(\"q, k, v:\", query.shape, key.shape, value.shape)\n",
        "    #     # Scaled dot product attention\n",
        "    #     scale = self.head_dim ** -0.5\n",
        "    #     attn_weights = self.attention(query, key, value, scale, attn_mask)\n",
        "\n",
        "    #     # Recombine heads\n",
        "    #     attn_out = attn_weights.transpose(1, 2).reshape(batch_size, seq_len, embed_dim)\n",
        "\n",
        "    #     # Final linear projection\n",
        "    #     attn_out = self.out_proj(attn_out)\n",
        "\n",
        "    #     return attn_out\n"
      ],
      "metadata": {
        "id": "ndlNfcgvhEGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim, hidden_dim, num_heads, dropout):\n",
        "       super().__init__()\n",
        "\n",
        "       self.embed_dim = embed_dim\n",
        "       self.hidden_dim = hidden_dim\n",
        "       self.num_heads = num_heads\n",
        "       self.dropout = dropout\n",
        "\n",
        "       self.attn = MultiHeadedAttention(embed_dim, num_heads, dropout)\n",
        "       self.ffn = FeedForwardNetwork(embed_dim, hidden_dim, dropout)\n",
        "\n",
        "       self.norm1 = nn.LayerNorm(embed_dim)\n",
        "       self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "       self.drop = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "\n",
        "      attn_out = self.attn(query=x, key=x, value=x, attn_mask=mask)\n",
        "      x = x + self.drop(self.norm1(attn_out))\n",
        "\n",
        "      ffn_out = self.ffn(x)\n",
        "      x = x + self.drop(self.norm2(ffn_out))\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "apSxbrnFZyZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, dropout, num_layers, num_heads):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers  # Add the num_layers hyperparameter\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        self.decoders = nn.ModuleList([DecoderBlock(embed_dim, hidden_dim, num_heads, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.out_proj = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "\n",
        "    def get_pos_matrix(self, x): #can be improved/see learned pos encoding & learned angle divisor param (instead of 10000)\n",
        "        print(x.shape)\n",
        "        batch_size, sequence_length = x.shape\n",
        "        store = torch.zeros((batch_size, sequence_length, self.embed_dim)).to(x.device)\n",
        "        for pos in range(sequence_length):\n",
        "            for i in range(0, self.embed_dim, 2):\n",
        "                denominator = 10000 ** (i / self.embed_dim)\n",
        "                angles = torch.tensor([pos / denominator])\n",
        "                store[:, pos, i] = torch.sin(angles)\n",
        "                if i + 1 < self.embed_dim:\n",
        "                    store[:, pos, i + 1] = torch.cos(angles)\n",
        "        return store\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.embedding(x) + self.get_pos_matrix(x)\n",
        "        print(\"x shape:\", x.shape)\n",
        "        sequence_length = x.shape[1]\n",
        "        # Create lower triangular mask\n",
        "        mask = torch.tril(torch.ones(batch_size, sequence_length, sequence_length)).to(x.device)\n",
        "        print(\"Mask shape:\", mask.shape)\n",
        "        for decoder in self.decoders:\n",
        "            x = decoder(x, mask)\n",
        "\n",
        "        x = self.layer_norm(x)\n",
        "\n",
        "        out = self.out_proj(x)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "InWcsAFJpOA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#debugging"
      ],
      "metadata": {
        "id": "LLXxBAI7MeNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "\n",
        "# # Model hyperparameters\n",
        "# vocab_size = 1000\n",
        "# embed_dim = 512\n",
        "# max_seq_len = 64\n",
        "# num_layers = 6\n",
        "# num_heads = 8\n",
        "\n",
        "# # Create dummy input\n",
        "# dummy_input = torch.rand(1, max_seq_len, embed_dim).long()\n",
        "\n",
        "# # Initialize model\n",
        "# model = Transformer(vocab_size, embed_dim, hidden_dim, dropout, num_layers, num_heads)\n",
        "\n",
        "# # Forward pass on dummy input\n",
        "# outputs = model(dummy_input)\n",
        "\n",
        "# # Print output shape\n",
        "# print(outputs.shape)\n",
        "\n",
        "# # Print attention scores shape for each layer\n",
        "# for i, attn in enumerate(model.attentions):\n",
        "#     print(f\"Layer {i} attention scores shape: {attn.shape}\")"
      ],
      "metadata": {
        "id": "eeCKnlNgMa17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running"
      ],
      "metadata": {
        "id": "iORFRj7vsdv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = Transformer(vocab_size, embed_dim, hidden_dim, dropout, num_layers, num_heads)\n",
        "opt = torch.optim.Adam(m.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"Parameters: \", m.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh-YD6WluX_K",
        "outputId": "7f5ea2bd-b48b-4e02-a8e2-dd48e229725a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:  <generator object Module.parameters at 0x7a6a0dd11e70>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "m.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymiZEFJy8PrI",
        "outputId": "42da2119-ed73-4000-d07c-7f0b29f82081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (embedding): Embedding(100, 128)\n",
              "  (decoders): ModuleList(\n",
              "    (0): DecoderBlock(\n",
              "      (attn): MultiHeadedAttention(\n",
              "        (q_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (k_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (v_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (attention): ScaledDotProductAttention(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): FeedForwardNetwork(\n",
              "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
              "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (relu): ReLU()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (out_proj): Linear(in_features=128, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_dir = 'models'\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(models_dir)\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "save_path = f\"models/{timestamp}_oddformer.pth\""
      ],
      "metadata": {
        "id": "VU2pWXt9Si3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise wandb\n",
        "wandb.init(\n",
        "  project=\"oddformer\",\n",
        "  name= \"multiheaded_oddformer, 1 epoch\",\n",
        "  config={\n",
        "  \"dataset\": \"sentences.txt\",\n",
        "  \"epochs\": num_epochs,\n",
        "  \"batch_size\": batch_size,\n",
        "  }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490,
          "referenced_widgets": [
            "5d1c58f1d1564d51828f64f120080645",
            "bb09eb5fca454f5dab76e26d79a12707",
            "e9740b546b524b8aa1f593eb9b057279",
            "08b222e597844dc2818c6bc5b9a5280b",
            "9a1d2726643740cca07f71bd223c26bb",
            "772f6598dacb49debad3e301b8d2c19a",
            "bbd34e3ca9084042a11501501b70b801",
            "e9868ec6084f47a0b0f7d76514641645"
          ]
        },
        "id": "nsp7r-DcYd8y",
        "outputId": "3d2cb522-1066-406a-b30f-09b582fb96df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668737166666385, max=1.0â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d1c58f1d1564d51828f64f120080645"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem at: <ipython-input-95-27f7f6f5ceb0> 2 <cell line: 2>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CommError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-27f7f6f5ceb0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialise wandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m wandb.init(\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"oddformer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"multiheaded_oddformer, 1 epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   config={\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mrun_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.config.update({\n",
        "  \"epochs\": num_epochs,\n",
        "  \"batch_size\": batch_size,\n",
        "  \"learning_rate\": lr\n",
        "})"
      ],
      "metadata": {
        "id": "puVTMhHRaGy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "\n",
        "  # Training loop\n",
        "  for X, y in train_loader:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    print(next(m.parameters()).device)\n",
        "    print(X.device, y.device)\n",
        "    outputs = m(X)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    wandb.log({\"Batch Loss\": loss.item()})\n",
        "\n",
        "  # Validation loop\n",
        "  val_loss = 0\n",
        "  val_accuracy = 0\n",
        "\n",
        "  for X, y in val_loader:\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    outputs = m(X)\n",
        "    loss = criterion(outputs, y)\n",
        "\n",
        "    val_loss += loss.item()\n",
        "    val_accuracy += (outputs.argmax(1) == y).sum().item() / len(y)\n",
        "\n",
        "  val_loss /= len(val_loader)\n",
        "\n",
        "  print(f\"Epoch {epoch} Validation Loss: {val_loss}\")\n",
        "  print(f\"Epoch {epoch} Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "  wandb.log({\"Val Loss\": val_loss, \"Val Accuracy\": val_accuracy})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "GpklOOMkYM1H",
        "outputId": "b65e4447-fdef-491e-a352-176ba01ec4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cuda:0 cuda:0\n",
            "torch.Size([100, 99])\n",
            "x shape: torch.Size([100, 99, 128])\n",
            "Mask shape: torch.Size([100, 99, 99])\n",
            "torch.Size([100, 99, 32])\n",
            "torch.Size([100, 99, 32]) torch.Size([100, 99, 32]) torch.Size([100, 99, 32])\n",
            "Scores shape: torch.Size([100, 99, 99])\n",
            "Scores shape after mask: torch.Size([100, 99, 99])\n",
            "torch.Size([100, 99, 32]) torch.Size([100, 99, 32]) torch.Size([100, 99, 32])\n",
            "Scores shape: torch.Size([100, 99, 99])\n",
            "Scores shape after mask: torch.Size([100, 99, 99])\n",
            "torch.Size([100, 99, 32]) torch.Size([100, 99, 32]) torch.Size([100, 99, 32])\n",
            "Scores shape: torch.Size([100, 99, 99])\n",
            "Scores shape after mask: torch.Size([100, 99, 99])\n",
            "torch.Size([100, 99, 32]) torch.Size([100, 99, 32]) torch.Size([100, 99, 32])\n",
            "Scores shape: torch.Size([100, 99, 99])\n",
            "Scores shape after mask: torch.Size([100, 99, 99])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-99c48e97fe84>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected target size [100, 100], got [100, 99]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(m.state_dict(), \"weights.pth\")\n",
        "wandb.save(\"weights.pth\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "UKgovTFSacPD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}